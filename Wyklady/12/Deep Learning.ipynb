{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning - Uczenie się cech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zródła\n",
    "\n",
    "* http://colah.github.io - Świetny blog o uczeniu głębokim\n",
    "\n",
    "### Blog nividii (dużo ciekawych rzeczy):\n",
    "\n",
    "Tłumaczenie neuronowe\n",
    "* http://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/\n",
    "* http://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/\n",
    "* http://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/\n",
    "\n",
    "Deeplearning in a Nutshell:\n",
    "* http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/\n",
    "* http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-history-training/\n",
    "* Trzecia częśc nadejdzie\n",
    "\n",
    "GPU Gems (o GPU w ogóle)\n",
    "\n",
    "* http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter45.html\n",
    "\n",
    "### YouTube\n",
    "\n",
    "* https://youtu.be/FwFduRA_L6Q\n",
    "* https://youtu.be/8BFzu9m52sc\n",
    "\n",
    "### Artykuły\n",
    "\n",
    "* Krizhevsky, A., Sutskever, I. and Hinton, G. E. ImageNet Classification with Deep Convolutional Neural Networks NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada, http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks\n",
    "\n",
    "### Czegoś nie ma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inżyniera cech vs. Uczenie się cech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pierwsza głęboka sieć neuronowa\n",
    "\n",
    "Ivakhnenko and Lapa (1965): Warstwy trenowane po kolei, algorytm propagacji wsteczniej jeszcze nie istniał.\n",
    "\n",
    "<img style=\"margin: auto\" width=\"60%\" src=\"http://devblogs.nvidia.com/parallelforall/wp-content/uploads/sites/3/2015/12/GMDH-network.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Propagcja wsteczna błędów (BP)\n",
    "* Wczesna niekompletna wersja BP w latach 60-tych\n",
    "* Linnainmaa 1970 (praca magisterska!): \n",
    "    * Pierwsza nowoczesna wersja\n",
    "    * Implementacja w FORTRANie\n",
    "    * Nie wspomniano wtedy o sieciach neuronowych\n",
    "* Rumelhart, Hinton, Williams (1985): Pierwsze wyniki dla BP i sieci neuronowych\n",
    "* LeCunn 1989 (Bell Labs): Pierwsze \"sensowne\" zastosowanie BP do sieci neuronowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Yann LeCun - LeNet\n",
    "\n",
    "    Y. LeCun, L. D. Jackel, B. Boser, J. S. Denker, H. P. Graf, I. Guyon, D. Henderson, R. E. Howard, and W. Hubbard. Handwritten digit recognition: Applications of neural net chips and automatic learning. IEEE Communication, pages 41-46, November 1989. invited paper.\n",
    "\n",
    "* 1993: https://youtu.be/FwFduRA_L6Q\n",
    "* teraz: http://www.jeanchristophebonis.com/2015/11/23/learn-more-about-facebook-ai-research-and-yann-lecun/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cortes and Vapnik (1995): Rozwój SVM przykrywa sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problem znikających gradientów (Vanishing Gradient Problem)\n",
    "\n",
    "* W głębokich sieciach neuronowych wagi były ograniczone do $[0,1]$ lub $[-1,1]$. \n",
    "* Mnożenie wielu małych wartości (tak się dzieje w BP w przypadku wielu warstw) prowadzi do zanikania wartości.\n",
    "\n",
    "Rozwiązania:\n",
    "* Nowe algorytmy optimalizacji (Rprop, RMSprop)\n",
    "* RELU\n",
    "* Dropout\n",
    "* Lepsza incjalizacja wag\n",
    "* LSTM (Long short term memory)\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GPU: Zwiększenie mocy obliczeniowej\n",
    "\n",
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://http.developer.nvidia.com/GPUGems2/elementLinks/45_finance_04.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ImageNet 2012: \n",
    "\n",
    "http://image-net.org/challenges/LSVRC/2012/ilsvrc2012.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ImageNet: Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton (2012)\n",
    "\n",
    "<img style=\"margin: auto\" width=\"60%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/KSH-arch.png\"/>\n",
    "\n",
    "    Krizhevsky, A., Sutskever, I. and Hinton, G. E. ImageNet Classification with Deep Convolutional Neural Networks NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada\n",
    "    \n",
    "| Model         | Top-1 | Top-5 |\n",
    "|---------------|-------|-------|\n",
    "| Sparse Coding | 47.1% | 28.2% |\n",
    "| SIFT+FVs      | 45.7% | 25.7% |\n",
    "| **CNN**           | 37.5% | 17.0% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sieci Konwolucyjne\n",
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv2-9x5-Conv2Max2Conv2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MNIST - Sieci Feedforward w Keras (Powtórka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "4s - loss: 0.2745 - acc: 0.9164 - val_loss: 0.1153 - val_acc: 0.9645\n",
      "Epoch 2/20\n",
      "4s - loss: 0.1135 - acc: 0.9659 - val_loss: 0.0928 - val_acc: 0.9708\n",
      "Epoch 3/20\n",
      "4s - loss: 0.0796 - acc: 0.9749 - val_loss: 0.0864 - val_acc: 0.9748\n",
      "Epoch 4/20\n",
      "4s - loss: 0.0631 - acc: 0.9802 - val_loss: 0.0650 - val_acc: 0.9796\n",
      "Epoch 5/20\n",
      "4s - loss: 0.0501 - acc: 0.9844 - val_loss: 0.0736 - val_acc: 0.9777\n",
      "Epoch 6/20\n",
      "4s - loss: 0.0411 - acc: 0.9868 - val_loss: 0.0585 - val_acc: 0.9827\n",
      "Epoch 7/20\n",
      "4s - loss: 0.0339 - acc: 0.9889 - val_loss: 0.0663 - val_acc: 0.9820\n",
      "Epoch 8/20\n",
      "4s - loss: 0.0302 - acc: 0.9902 - val_loss: 0.0626 - val_acc: 0.9823\n",
      "Epoch 9/20\n",
      "4s - loss: 0.0260 - acc: 0.9918 - val_loss: 0.0653 - val_acc: 0.9822\n",
      "Epoch 10/20\n",
      "4s - loss: 0.0211 - acc: 0.9935 - val_loss: 0.0620 - val_acc: 0.9820\n",
      "Epoch 11/20\n",
      "4s - loss: 0.0204 - acc: 0.9934 - val_loss: 0.0568 - val_acc: 0.9847\n",
      "Epoch 12/20\n",
      "4s - loss: 0.0177 - acc: 0.9944 - val_loss: 0.0727 - val_acc: 0.9819\n",
      "Epoch 13/20\n",
      "4s - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0562 - val_acc: 0.9853\n",
      "Epoch 14/20\n",
      "4s - loss: 0.0126 - acc: 0.9959 - val_loss: 0.0620 - val_acc: 0.9851\n",
      "Epoch 15/20\n",
      "4s - loss: 0.0125 - acc: 0.9957 - val_loss: 0.0618 - val_acc: 0.9849\n",
      "Epoch 16/20\n",
      "4s - loss: 0.0131 - acc: 0.9956 - val_loss: 0.0680 - val_acc: 0.9832\n",
      "Epoch 17/20\n",
      "4s - loss: 0.0098 - acc: 0.9965 - val_loss: 0.0682 - val_acc: 0.9849\n",
      "Epoch 18/20\n",
      "4s - loss: 0.0098 - acc: 0.9964 - val_loss: 0.0664 - val_acc: 0.9854\n",
      "Epoch 19/20\n",
      "4s - loss: 0.0092 - acc: 0.9970 - val_loss: 0.0637 - val_acc: 0.9834\n",
      "Epoch 20/20\n",
      "4s - loss: 0.0090 - acc: 0.9971 - val_loss: 0.0685 - val_acc: 0.9855\n",
      "Test score: 0.0684883500228\n",
      "Test accuracy: 0.9855\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 20\n",
    "\n",
    "# the data, shuffled and split between tran and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "rms = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          show_accuracy=True, verbose=2,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                       show_accuracy=True, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Konwolucje w sieciach neuronowych (1D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv-9-xs.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv-9-F.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv-9-Conv2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv-9-Conv3.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv-9-Conv2Conv2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv-9-Conv2Max2Conv2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Warstwa konwolucyjna w Keras (1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 100, input_length=100))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution1D(nb_filter=250,\n",
    "                        filter_length=3,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "model.add(MaxPooling1D(pool_length=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 100\n",
    "batch_size = 32\n",
    "embedding_dims = 100\n",
    "nb_filter = 250\n",
    "filter_length = 3\n",
    "hidden_dims = 250\n",
    "nb_epoch = 2\n",
    "\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features,\n",
    "                                                      test_split=0.2)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features, embedding_dims, input_length=maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# we add a Convolution1D, which will learn nb_filter\n",
    "# word group filters of size filter_length:\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "# we use standard max pooling (halving the output of the previous layer):\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "# We flatten the output of the conv layer,\n",
    "# so that we can add a vanilla dense layer:\n",
    "model.add(Flatten())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              class_mode='binary')\n",
    "model.fit(X_train, y_train, batch_size=batch_size,\n",
    "          nb_epoch=nb_epoch, show_accuracy=True,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Konwolucje w przetwarzaniu obrazów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"60%\" src=\"http://devblogs.nvidia.com/parallelforall/wp-content/uploads/sites/3/2015/11/convolution.png\"/>\n",
    "\n",
    "<img style=\"margin: auto\" width=\"60%\" src=\"http://devblogs.nvidia.com/parallelforall/wp-content/uploads/sites/3/2015/11/Convolution_schematic.gif\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Konwolucje 2D formalnie\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{ccc}\n",
    "a & b & c\\\\\n",
    "d & e & f\\\\\n",
    "g & h & i\\\\\n",
    "\\end{array}\\right]\n",
    "*\n",
    "\\left[\\begin{array}{ccc}\n",
    "1 & 2 & 3\\\\\n",
    "3 & 4 & 5\\\\\n",
    "6 & 7 & 8\\\\\n",
    "\\end{array}\\right] \n",
    "=\\\\\n",
    "(1 \\cdot i)+(2\\cdot h)+(3\\cdot g)+(4 \\cdot f)+(5\\cdot e)\\\\+(6\\cdot d)+(7\\cdot c)+(8\\cdot b)+(9\\cdot a)\n",
    "$$\n",
    "\n",
    "Więcej: https://en.wikipedia.org/wiki/Kernel_(image_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Konwolucje w sieciach neuronowych (2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"margin: auto\" width=\"30%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv2-unit.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv2-9x5-Conv2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv2-9x5-Conv2Conv2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv2-9x5-Conv2Max2Conv2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Struktura jednostki konwolucyjnej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"60%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv-A.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"60%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv-A-NIN.png\"/>\n",
    "\n",
    "Więcej na: http://colah.github.io/posts/2014-07-Conv-Nets-Modular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ImageNet: Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton (2012)\n",
    "\n",
    "<img style=\"margin: auto\" width=\"60%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/KSH-arch.png\"/>\n",
    "\n",
    "    Krizhevsky, A., Sutskever, I. and Hinton, G. E. ImageNet Classification with Deep Convolutional Neural Networks NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada\n",
    "    \n",
    "| Model         | Top-1 | Top-5 |\n",
    "|---------------|-------|-------|\n",
    "| Sparse Coding | 47.1% | 28.2% |\n",
    "| SIFT+FVs      | 45.7% | 25.7% |\n",
    "| **CNN**           | 37.5% | 17.0% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"https://flickrcode.files.wordpress.com/2014/10/conv-net2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/KSH-results.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/KSH-filters.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Warstwa konwolucyjna i max-pooling w Keras (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(1, 28, 28)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MNIST - Sieci konwolucyjne w Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 1, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 9s - loss: 0.2332 - acc: 0.9285 - val_loss: 0.0558 - val_acc: 0.9832\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 8s - loss: 0.0871 - acc: 0.9738 - val_loss: 0.0408 - val_acc: 0.9860\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s - loss: 0.0675 - acc: 0.9802 - val_loss: 0.0329 - val_acc: 0.9890\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s - loss: 0.0537 - acc: 0.9835 - val_loss: 0.0316 - val_acc: 0.9892\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s - loss: 0.0483 - acc: 0.9851 - val_loss: 0.0313 - val_acc: 0.9895\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s - loss: 0.0406 - acc: 0.9870 - val_loss: 0.0330 - val_acc: 0.9886\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s - loss: 0.0388 - acc: 0.9880 - val_loss: 0.0282 - val_acc: 0.9913\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s - loss: 0.0344 - acc: 0.9892 - val_loss: 0.0282 - val_acc: 0.9905\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 8s - loss: 0.0288 - acc: 0.9911 - val_loss: 0.0264 - val_acc: 0.9924\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s - loss: 0.0290 - acc: 0.9910 - val_loss: 0.0268 - val_acc: 0.9920\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 8s - loss: 0.0281 - acc: 0.9910 - val_loss: 0.0264 - val_acc: 0.9923\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s - loss: 0.0249 - acc: 0.9915 - val_loss: 0.0324 - val_acc: 0.9917\n",
      "Test score: 0.0323923342442\n",
      "Test accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "# the data, shuffled and split between tran and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(1, img_rows, img_cols)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adadelta')\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RNN i LSTM - Przetwarzanie sekwencji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"20%\" src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-rolled.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Zależności długodystansowe (Long-distance dependencies)\n",
    "\n",
    "<img style=\"margin: auto\" width=\"60%\" src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-shorttermdepdencies.png\"/>\n",
    "\n",
    "<img style=\"margin: auto\" width=\"60%\" src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-longtermdependencies.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## LSTM: http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Generowanie Tekstu (litera po literze)\n",
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://karpathy.github.io/assets/rnn/charseq.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Generator ''Szekspira''\n",
    "\n",
    "PANDARUS:<br/>\n",
    "Alas, I think he shall be come approached and the day<br/>\n",
    "When little srain would be attain'd into being never fed,<br/>\n",
    "And who is but a chain and subjects of his death, <br/>\n",
    "I should not sleep.\n",
    "\n",
    "Second Senator:<br/>\n",
    "They are away this miseries, produced upon my soul, <br/>\n",
    "Breaking and strongly should be buried, when I perish<br/>\n",
    "The earth and thoughts of many states.<br/>\n",
    "\n",
    "DUKE VINCENTIO:<br/>\n",
    "Well, your wit is in the care of side and that.<br/>\n",
    "\n",
    "Second Lord:<br/>\n",
    "They would be ruled after this chamber, and <br/>\n",
    "my fair nues begun out of the fact, to be conveyed,<br/>\n",
    "Whose noble souls I'll have the heart of the wars.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tłumaczenie neuronowe\n",
    "<img style=\"margin: auto\" width=\"80%\" src=\"http://devblogs.nvidia.com/parallelforall/wp-content/uploads/sites/3/2015/06/Figure2_NMT_system.png\"/>\n",
    "[NMT](http://104.131.78.120/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Generowanie opisów\n",
    "<img style=\"margin: auto\" width=\"100%\" src=\"nic_rated.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Schemat sieci\n",
    "\n",
    "<img style=\"margin: auto\" width=\"80%\" src=\"nn_c.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/8BFzu9m52sc\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fa96ed3fbd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"8BFzu9m52sc\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
